{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\xStyNWx\\Documents\\BINUS University\\Academic Courses\\Semester 4\\Natural Language Processing\\Project\\Repo\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 272.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model, Tokenizer, dan TF-IDF Vectorizer berhasil disimpan di folder 'saved_preprocessing_model/'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLP resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Lemmatizer & Stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load dataset ACLSum\n",
    "dataset = load_dataset(\"sobamchan/aclsum\", split=\"train\")\n",
    "\n",
    "# Function untuk membersihkan teks\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'\\d+', '', text)  # Menghapus angka\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Menghapus tanda baca\n",
    "    words = word_tokenize(text)  # Tokenisasi\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatization & stopword removal\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Preprocessing seluruh dataset\n",
    "for entry in dataset:\n",
    "    entry['document'] = clean_text(entry['document'])\n",
    "    entry['outcome'] = clean_text(entry['outcome'])\n",
    "\n",
    "# Inisialisasi tokenizer T5\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Function untuk tokenisasi dengan padding dan truncation\n",
    "def preprocess_data(example):\n",
    "    inputs = tokenizer(example['document'], max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(example['outcome'], max_length=150, truncation=True, padding=\"max_length\")\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Tokenisasi dataset\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# Inisialisasi model T5\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Menggunakan TF-IDF Vectorizer sebagai tambahan fitur\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Mengambil 5000 fitur paling penting\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([entry['document'] for entry in dataset])\n",
    "\n",
    "# Simpan model, tokenizer, dan TF-IDF vectorizer setelah training\n",
    "model.save_pretrained(\"saved_preprocessing_model\")\n",
    "tokenizer.save_pretrained(\"saved_preprocessing_model\")\n",
    "\n",
    "# Simpan TF-IDF vectorizer menggunakan pickle\n",
    "with open(\"saved_preprocessing_model/tfidf_vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tfidf_vectorizer, file)\n",
    "\n",
    "print(\"✅ Model, Tokenizer, dan TF-IDF Vectorizer berhasil disimpan di folder 'saved_preprocessing_model/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model, Tokenizer, dan TF-IDF Vectorizer berhasil dimuat kembali!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load model yang telah disimpan\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"saved_preprocessing_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"saved_preprocessing_model\")\n",
    "\n",
    "# Load TF-IDF Vectorizer\n",
    "with open(\"saved_preprocessing_model/tfidf_vectorizer.pkl\", \"rb\") as file:\n",
    "    tfidf_vectorizer = pickle.load(file)\n",
    "\n",
    "print(\"✅ Model, Tokenizer, dan TF-IDF Vectorizer berhasil dimuat kembali!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Paper (Cleaned):\n",
      " In this paper , we explore correlation of dependency relation paths to rank candidate answers in answer extraction . Using the correlation measure , we compare dependency relations of a candidate answer and mapped question phrases in sentence with the corresponding relations in question . Different from previous studies , we propose an approximate phrase mapping algorithm and incorporate the mapping score into the correlation measure . The correlations are further incorporated into a Maximum Entropy-based ranking model which estimates path weights from training . Experimental results show that our method significantly outperforms state-ofthe-art syntactic relation-based methods by up to 20 % in MRR . Answer Extraction is one of basic modules in open domain Question Answering ( QA ) . It is to further process relevant sentences extracted with Passage / Sentence Retrieval and pinpoint exact answers using more linguistic-motivated analysis . Since QA turns to find exact answers rather than text snippets in recent years , answer extraction becomes more and more crucial . Typically , answer extraction works in the following steps : • Recognize expected answer type of a question . • Annotate relevant sentences with various types of named entities . • Regard the phrases annotated with the expected answer type as candidate answers . • Rank candidate answers . In the above work flow , answer extraction heavily relies on named entity recognition ( NER ) . On one hand , NER reduces the number of candidate answers and eases answer ranking . On the other hand , the errors from NER directly degrade answer extraction performance . To our knowledge , most top ranked QA systems in TREC are supported by effective NER modules which may identify and classify more than 20 types of named entities ( NE ) , such as abbreviation , music , movie , etc . However , developing such named entity recognizer is not trivial . Up to now , we have n't found any paper relevant to QA-specific NER development . So , it is hard to follow their work . In this paper , we just use a general MUC-based NER , which makes our results reproducible . A general MUC-based NER ca n't annotate a large number of NE classes . In this case , all noun phrases in sentences are regarded as candidate answers , which makes candidate answer sets much larger than those filtered by a well developed NER . The larger candidate answer sets result in the more difficult answer extraction . Previous methods working on surface word level , such as density-based ranking and pattern matching , may not perform well . Deeper linguistic analysis has to be conducted . This paper proposes a statistical method which exploring correlation of dependency relation paths to rank candidate answers . It is motivated by the observation that relations between proper answers and question phrases in candidate sentences are always similar to the corresponding relations in question . For example , the question \" What did Alfred Nobel invent ? \" and the candidate sentence \" ... in the will of Swedish industrialist Alfred Nobel , who invented dynamite . \" For each question , firstly , dependency relation paths are defined and extracted from the question and each of its candidate sentences . Secondly , the paths from the question and the candidate sentence are paired according to question phrase mapping score . Thirdly , correlation between two paths of each pair is calculated by employing Dynamic Time Warping algorithm . The input of the calculation is correlations between dependency relations , which are estimated from a set of training path pairs . Lastly , a Maximum Entropy-based ranking model is proposed to incorporate the path correlations and rank candidate answers . Furthermore , sentence supportive measure are presented according to correlations of relation paths among question phrases . It is applied to re-rank the candidate answers extracted from the different candidate sentences . Considering phrases may provide more accurate information than individual words , we extract dependency relations on phrase level instead of word level . The experiment on TREC questions shows that our method significantly outperforms a densitybased method by 50 % in MRR and three stateof-the-art syntactic-based methods by up to 20 % in MRR . Furthermore , we classify questions by judging whether NER is used . We investigate how these methods perform on the two question sets . The results indicate that our method achieves better performance than the other syntactic-based methods on both question sets . Especially for more difficult questions , for which NER may not help , our method improves MRR by up to 31 % . The paper is organized as follows . Section 2 discusses related work and clarifies what is new in this paper . Section 3 presents relation path correlation in detail . Section 4 and 5 discuss how to incorporate the correlations for answer ranking and re-ranking . Section 6 reports experiment and results . In this paper , we propose a relation path correlation-based method to rank candidate answers in answer extraction . We extract and pair relation paths from questions and candidate sentences . Next , we measure the relation path correlation in each pair based on approximate phrase mapping score and relation sequence alignment , which is calculated by DTW algorithm . Lastly , a ME-based ranking model is proposed to incorporate the path correlations and rank candidate answers . The experiment on TREC questions shows that our method significantly outperforms a density-based method by 50 % in MRR and three state-of-the-art syntactic-based methods by up to 20 % in MRR . Furthermore , the method is especially effective for difficult questions , for which NER may not help . Therefore , it may be used to further enhance state-of-the-art QA systems even if they have a good NER . In the future , we are to further evaluate the method based on the overall performance of a QA system and adapt it to sentence retrieval task .\n",
      "\n",
      "Generated Summary:\n",
      " . The results show that our method significantly outperforms a density-based method by 50 % in MRR. NER reduces the number of candidate answers and eases answer ranking.\n",
      "\n",
      "TF-IDF Features for Sample Paper:\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Function untuk membuat ringkasan dengan model yang telah disimpan\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Contoh penggunaan dengan dokumen yang sudah diproses\n",
    "sample_paper = dataset[0]['document']\n",
    "print(\"\\nOriginal Paper (Cleaned):\\n\", sample_paper)\n",
    "print(\"\\nGenerated Summary:\\n\", generate_summary(sample_paper))\n",
    "\n",
    "# Menggunakan TF-IDF Vectorizer untuk representasi numerik teks\n",
    "tfidf_features = tfidf_vectorizer.transform([sample_paper])\n",
    "print(\"\\nTF-IDF Features for Sample Paper:\\n\", tfidf_features.toarray()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Paper (Cleaned):\n",
      " Automatically extracting social meaning and intention from spoken dialogue is an important task for dialogue systems and social computing . We describe a system for detecting elements of interactional style : whether a speaker is awkward , friendly , or flirtatious . We create and use a new spoken corpus of 991 4-minute speed-dates . Participants rated their interlocutors for these elements of style . Using rich dialogue , lexical , and prosodic features , we are able to detect flirtatious , awkward , and friendly styles in noisy natural conversational data with up to 75 % accuracy , compared to a 50 % baseline . We describe simple ways to extract relatively rich dialogue features , and analyze which features performed similarly for men and women and which were gender-specific . How can we extract social meaning from speech , deciding if a speaker is particularly engaged in the conversation , is uncomfortable or awkward , or is particularly friendly and flirtatious ? Understanding these meanings and how they are signaled in language is an important sociolinguistic task in itself . Extracting them automatically from dialogue speech and text is crucial for developing socially aware computing systems for tasks such as detection of interactional problems or matching conversational style , and will play an important role in creating more natural dialogue agents ( Pentland , 2005 ; Nass and Brave , 2005 ; Brave et al . , 2005 ) . Cues for social meaning permeate speech at every level of linguistic structure . Acoustic cues such as low and high F0 or energy and spectral tilt are important in detecting emotions such as annoyance , anger , sadness , or boredom ( Ang et al . , 2002 ; Lee and Narayanan , 2002 ; Liscombe et al . , 2003 ) , speaker characteristics such as charisma ( Rosenberg and Hirschberg , 2005 ) , or personality features like extroversion ( Mairesse et al . , 2007 ; Mairesse and Walker , 2008 ) . Lexical cues to social meaning abound . Speakers with links to depression or speakers who are under stress use more first person singular pronouns ( Rude et al . , 2004 ; Pennebaker and Lay , 2002 ; Cohn et al . , 2004 ) , positive emotion words are cues to agreeableness ( Mairesse et al . , 2007 ) , and negative emotion words are useful cues to deceptive speech ( Newman et al . , 2003 ) . The number of words in a sentence can be a useful feature for extroverted personality ( Mairesse et al . , 2007 ) . Finally , dialog features such as the presence of disfluencies can inform listeners about speakers ' problems in utterance planning or about confidence ( Brennan and Williams , 1995 ; Brennan and Schober , 2001 ) . Our goal is to see whether cues of this sort are useful in detecting particular elements of conversational style and social intention ; whether a speaker in a speed-dating conversation is judged by the interlocutor as friendly , awkward , or flirtatious . The results presented here should be regarded with some caution . The sample is not a random sample of English speakers or American adults , and speed dating is not a natural context for expressing every conversational style . Therefore , a wider array of studies across populations and genres would be required before a more general theory of conversational styles is established . On the other hand , the presented results may under-reflect the relations being captured . The quality of recordings and coarse granularity ( 1 second ) of the time-stamps likely cloud the relations , and as the data is cleaned and improved , we expect the associations to only grow stronger . Caveats aside , we believe the evidence indicates that the perception of several types of conversational style have relatively clear signals across genders , but with some additional gender contextualization . Both genders convey flirtation by laughing more , speaking faster , and using higher and more variable pitch . Both genders convey friendliness by laughing more , and using collaborative completions . However , we do find gender differences ; men asl more questions when ( labeled as ) flirting , women ask fewer . Men labeled as flirting are softer , but women labeled as flirting are louder . Women flirt-ing swear more , while men are more likely to use sexual vocabulary . Gender differences exist as well for the other variables . Men labeled as friendly use you while women labeled as friendly use I. Friendly women are very disfluent ; friendly men are not . While the features for friendly and flirtatious speech overlap , there are clear differences . Men speaker faster and with higher f0 ( min ) in flirtatious speech , but not faster and with lower f0 ( min ) in friendly speech . For men , flirtatious speech involves more questions and repair questions , while friendly speech does not . For women , friendly speech is more disfluent than flirtatious speech , and has more collaborative style ( completions , repair questions , appreciations ) . We also seem to see a model of collaborative conversational style ( probably related to the collaborative floor of Edelsky ( 1981 ) and Coates ( 1996 ) ) , cued by the use of more collaborative completions , repair questions and other questions , you , and laughter . These collaborative techniques were used by both women and men who were labeled as friendly , and occurred less with men labeled as awkward . Women themselves displayed more of this collaborative conversational style when they labeled the men as friendly . For women only , collaborative style included appreciations ; while for men only , collaborative style included overlaps . In addition to these implications for social science , our work has implications for the extraction of meaning in general . A key focus of our work was on ways to extract useful dialog act and disfluency features ( repair questions , backchannels , appreciations , restarts , dispreferreds ) with very shallow methods . These features were indeed extractable and proved to be useful features in classification . We are currently extending these results to predict date outcomes including ' liking ' , extending work such as Madan and Pentland ( 2006 ) .\n",
      "\n",
      "Generated Summary:\n",
      " . We create a new spoken corpus of 991 4-minute speed-dates. Participants rated their interlocutors for these elements of style. Using rich dialogue, lexical, and prosodic features, we are able to detect flirtatious, awkward, and friendly styles.\n",
      "\n",
      "TF-IDF Features for Sample Paper:\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Function untuk membuat ringkasan dengan model yang telah disimpan\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Contoh penggunaan dengan dokumen yang sudah diproses\n",
    "sample_paper = dataset[10]['document']\n",
    "print(\"\\nOriginal Paper (Cleaned):\\n\", sample_paper)\n",
    "print(\"\\nGenerated Summary:\\n\", generate_summary(sample_paper))\n",
    "\n",
    "# Menggunakan TF-IDF Vectorizer untuk representasi numerik teks\n",
    "tfidf_features = tfidf_vectorizer.transform([sample_paper])\n",
    "print(\"\\nTF-IDF Features for Sample Paper:\\n\", tfidf_features.toarray()[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
